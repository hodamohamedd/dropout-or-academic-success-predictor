{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "/usr/bin/env python\n",
        "coding: utf-8\n",
        "# Student Dropout Prediction: Exploratory Data Analysis\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis on the \"Dropout or Academic Success\" dataset to understand the data structure, distributions, and relationships between features.\n",
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries\n",
        "Set up plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset\n",
        "## 2. Basic Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading dataset...\")\n",
        "data_path = '../data/dataset.csv'  # Update this path if needed\n",
        "df = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display basic information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Data types:\")\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basic statistics\n",
        "## 3. Missing Values Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Basic statistics:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for missing values\n",
        "Calculate missing value percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Missing values per column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "missing_percent = (missing_values / len(df)) * 100\n",
        "missing_data = pd.DataFrame({\n",
        "    'Missing Values': missing_values,\n",
        "    'Percentage': missing_percent\n",
        "})\n",
        "\n",
        "print(\"\\nMissing values summary:\")\n",
        "print(missing_data[missing_data['Missing Values'] > 0].sort_values('Percentage', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize missing values if any exist\n",
        "## 4. Target Variable Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if missing_values.sum() > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(df.isnull(), cbar=True, cmap='viridis')\n",
        "    plt.title('Missing Values Heatmap')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../data/missing_values_heatmap.png')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No missing values found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze target variable distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Target variable distribution:\")\n",
        "target_col = 'Target'  # Update this to the actual target column name\n",
        "target_counts = df[target_col].value_counts()\n",
        "target_percent = target_counts / len(df) * 100\n",
        "\n",
        "print(\"Target distribution:\")\n",
        "print(pd.DataFrame({\n",
        "    'Count': target_counts,\n",
        "    'Percentage': target_percent\n",
        "}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot target distribution\n",
        "Add percentage labels on bars\n",
        "## 5. Feature Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.countplot(x=target_col, data=df)\n",
        "plt.title('Distribution of Target Classes')\n",
        "\n",
        "for p in ax.patches:\n",
        "    percentage = f'{100 * p.get_height() / len(df):.1f}%'\n",
        "    x = p.get_x() + p.get_width() / 2\n",
        "    y = p.get_height()\n",
        "    ax.annotate(percentage, (x, y), ha='center', va='bottom')\n",
        "\n",
        "plt.savefig('../data/target_distribution.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Identify numerical and categorical features\n",
        "Remove target column from feature lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "if target_col in numerical_cols:\n",
        "    numerical_cols.remove(target_col)\n",
        "if target_col in categorical_cols:\n",
        "    categorical_cols.remove(target_col)\n",
        "\n",
        "print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
        "print(f\"Numerical features: {numerical_cols[:10]}...\")  # Show first 10\n",
        "\n",
        "print(f\"\\nNumber of categorical features: {len(categorical_cols)}\")\n",
        "print(f\"Categorical features: {categorical_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze numerical feature distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(numerical_cols) > 0:\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    num_plots = min(9, len(numerical_cols))\n",
        "    for i, col in enumerate(numerical_cols[:num_plots], 1):\n",
        "        plt.subplot(3, 3, i)\n",
        "        sns.histplot(df[col], kde=True)\n",
        "        plt.title(f'Distribution of {col}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../data/numerical_distributions.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze categorical feature distributions\n",
        "## 6. Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(categorical_cols) > 0:\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    num_plots = min(9, len(categorical_cols))\n",
        "    for i, col in enumerate(categorical_cols[:num_plots], 1):\n",
        "        plt.subplot(3, 3, i)\n",
        "        value_counts = df[col].value_counts()\n",
        "        if len(value_counts) <= 10:  # Only plot if not too many categories\n",
        "            sns.barplot(x=value_counts.index, y=value_counts.values)\n",
        "            plt.title(f'Distribution of {col}')\n",
        "            plt.xticks(rotation=45)\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, f'{col}\\nToo many categories\\n({len(value_counts)} unique values)', \n",
        "                    ha='center', va='center', transform=plt.gca().transAxes)\n",
        "            plt.title(f'Distribution of {col}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../data/categorical_distributions.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate correlation matrix for numerical features\n",
        "Plot correlation heatmap\n",
        "Find highly correlated features\n",
        "## 7. Feature Relationships with Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(numerical_cols) > 1:\n",
        "    print(\"Calculating correlation matrix...\")\n",
        "    correlation = df[numerical_cols].corr()\n",
        "    \n",
        "    plt.figure(figsize=(14, 12))\n",
        "    sns.heatmap(correlation, annot=True, cmap='coolwarm', linewidths=0.5, fmt=\".2f\")\n",
        "    plt.title('Correlation Matrix of Numerical Features')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../data/correlation_heatmap.png')\n",
        "    plt.show()\n",
        "    \n",
        "    high_corr_threshold = 0.8\n",
        "    high_corr_pairs = []\n",
        "    for i in range(len(correlation.columns)):\n",
        "        for j in range(i+1, len(correlation.columns)):\n",
        "            if abs(correlation.iloc[i, j]) > high_corr_threshold:\n",
        "                high_corr_pairs.append((correlation.columns[i], correlation.columns[j], correlation.iloc[i, j]))\n",
        "    \n",
        "    if high_corr_pairs:\n",
        "        print(\"Highly correlated feature pairs (|correlation| > 0.8):\")\n",
        "        for pair in high_corr_pairs:\n",
        "            print(f\"{pair[0]} and {pair[1]}: {pair[2]:.3f}\")\n",
        "    else:\n",
        "        print(\"No highly correlated feature pairs found.\")\n",
        "else:\n",
        "    print(\"Not enough numerical features for correlation analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze relationship between numerical features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(numerical_cols) > 0:\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    num_plots = min(9, len(numerical_cols))\n",
        "    for i, col in enumerate(numerical_cols[:num_plots], 1):\n",
        "        plt.subplot(3, 3, i)\n",
        "        sns.boxplot(x=target_col, y=col, data=df)\n",
        "        plt.title(f'{col} by {target_col}')\n",
        "        plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../data/numerical_vs_target.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze relationship between categorical features and target\n",
        "Create a crosstab\n",
        "Plot\n",
        "## 8. Statistical Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(categorical_cols) > 0:\n",
        "    for col in categorical_cols[:5]:  # Analyze first 5 categorical features\n",
        "        if df[col].nunique() <= 10:  # Only analyze if not too many categories\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            \n",
        "            ct = pd.crosstab(df[col], df[target_col])\n",
        "            ct_pct = ct.div(ct.sum(axis=1), axis=0) * 100\n",
        "            \n",
        "            ct_pct.plot(kind='bar', stacked=True)\n",
        "            plt.title(f'{col} vs {target_col}')\n",
        "            plt.ylabel('Percentage')\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'../data/{col}_vs_target.png')\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== EXPLORATORY DATA ANALYSIS SUMMARY ===\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
        "print(f\"Number of categorical features: {len(categorical_cols)}\")\n",
        "print(f\"Missing values: {missing_values.sum()} total\")\n",
        "print(f\"Target variable: {target_col}\")\n",
        "print(f\"Target classes: {df[target_col].unique()}\")\n",
        "print(f\"Target distribution: {df[target_col].value_counts().to_dict()}\")\n",
        "\n",
        "print(\"\\nKey insights:\")\n",
        "if len(high_corr_pairs) > 0:\n",
        "    print(f\"- Found {len(high_corr_pairs)} highly correlated feature pairs\")\n",
        "else:\n",
        "    print(\"- No highly correlated features detected\")\n",
        "\n",
        "if missing_values.sum() > 0:\n",
        "    print(f\"- {(missing_values > 0).sum()} features have missing values\")\n",
        "else:\n",
        "    print(\"- No missing values found\")\n",
        "\n",
        "print(\"\\nVisualizations saved to the data directory:\")\n",
        "print(\"- target_distribution.png\")\n",
        "print(\"- correlation_heatmap.png\") \n",
        "print(\"- numerical_distributions.png\")\n",
        "print(\"- categorical_distributions.png\")\n",
        "print(\"- numerical_vs_target.png\")\n",
        "print(\"- [feature_name]_vs_target.png (for categorical features)\")\n",
        "\n",
        "print(\"\\nExploratory analysis complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
